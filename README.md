Project for playing a ML based PacMan game with gestures from camera as input for training and live play. Visualized the game play with features like accuracy, loss curve, UMAP, Confidence score display, real time gesture feedback using React. 

ML-PACMAN: Gesture-Controlled Pac-Man

ML-PACMAN is an interactive, browser-based adaptation of the classic Pac-Man game that leverages hand gestures for control. A fine-tuned MobileNet model powers gesture recognition, enabling players to navigate the game without a traditional keyboard or controller. Additionally, a dashboard provides real-time insights into model performance and gameplay metrics. This project builds upon the work of @wangqianwen0418.

üéÆ Demo

Check out the demo 



‚ú® Features

Custom Gesture Recognition: Train a MobileNet model to recognize and map hand gestures to game controls.

Real-Time Interaction: Use your webcam to control Pac-Man through intuitive hand movements.

Performance Metrics: View loss rates, confidence scores, and other key model performance statistics.

Data Visualization: Utilize UMAP to explore and analyze input datasets.

Classic Gameplay: Enjoy Pac-Man‚Äôs familiar mechanics with an innovative twist.

üîß Technologies Used

React: Frontend framework for building an interactive user interface.

TensorFlow.js: Deploys and runs the trained model directly in the browser.

MobileNet: Pre-trained model fine-tuned for hand gesture recognition.

D3.js: Provides interactive data visualizations.

WebRTC: Enables real-time webcam access for gesture detection.

üöÄ Installation

Follow these steps to set up and run ML-PACMAN on your local machine:

Clone the repository

git clone https://github.com/GayathriBalaji98/VisualizationWithAIPacMan.git
cd VisualizationWithAIPacMan

Install dependencies

npm install

Start the development server

npm start

ü§ù Contributing

We welcome contributions! If you have ideas for improvements or bug fixes, feel free to open a pull request.

Enjoy the game and happy coding! üéâ

